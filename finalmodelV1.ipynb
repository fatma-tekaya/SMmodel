{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Columns: Index(['Time (s)', ' HR (BPM)', ' RESP (BPM)', ' SpO2 (%)', 'TEMP (*C)',\n",
      "       'OUTPUT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load the data\n",
    "data_path = 'C:/Users/octanet/Desktop/PFE/smartwatchModel/Human_vital_signs_R.csv'\n",
    "health_data = pd.read_csv(data_path, index_col=[0])\n",
    "\n",
    "# Verify column names\n",
    "print(\"Training Data Columns:\", health_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Columns: Index([' HR (BPM)', ' SpO2 (%)', 'TEMP (*C)', 'OUTPUT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop the 'RESP (BPM)' and 'Time (s)' column\n",
    "health_data = health_data.drop(columns=[' RESP (BPM)'])\n",
    "health_data = health_data.drop(columns=['Time (s)'])\n",
    "print(\"Training Data Columns:\", health_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the target and features\n",
    "y = health_data['OUTPUT']\n",
    "X = health_data.drop(['OUTPUT'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94422217 0.9767004  0.92832765]\n",
      "Mean cross-validation score: 0.949750071689223\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline for imputation and model training\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', RandomForestClassifier(n_estimators=500, max_depth=7))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(my_pipeline, X, y, cv=3, scoring='accuracy')\n",
    "print('Cross-validation scores:', cv_scores)\n",
    "print('Mean cross-validation score:', cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model on the entire training set\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = my_pipeline.predict(X_test)\n",
    "\n",
    "# Enregistrer le mod√®le\n",
    "joblib.dump(my_pipeline, 'model.pkl')\n",
    "print(f\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test set: 0.9915669739164542\n",
      "Confusion Matrix:\n",
      "[[3896   21]\n",
      " [  22 1160]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.99      0.99      0.99      3917\n",
      "      Normal       0.98      0.98      0.98      1182\n",
      "\n",
      "    accuracy                           0.99      5099\n",
      "   macro avg       0.99      0.99      0.99      5099\n",
      "weighted avg       0.99      0.99      0.99      5099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score on the test set:', accuracy)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Columns: Index(['created_at', 'entry_id', 'TEMP (*C)', ' HR (BPM)', ' SpO2 (%)',\n",
      "       'latitude', 'longitude', 'elevation', 'OUTPUT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the new data for testing\n",
    "new_data_path = 'C:/Users/octanet/Desktop/PFE/smartwatchModel/feeds1.csv'\n",
    "new_data = pd.read_csv(new_data_path)\n",
    "\n",
    "# Verify and rename columns to match training data\n",
    "new_data = new_data.rename(columns={\n",
    "    'field1': 'TEMP (*C)',\n",
    "    'field2': ' HR (BPM)',\n",
    "    'field3': ' SpO2 (%)',\n",
    "    'status': 'OUTPUT',\n",
    "})\n",
    "# Verify column names\n",
    "print(\"Training Data Columns:\", new_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant columns for prediction\n",
    "X_new = new_data[[' HR (BPM)', ' SpO2 (%)', 'TEMP (*C)']]\n",
    "\n",
    "# Preprocess the new data using the same pipeline\n",
    "X_new_imputed = pd.DataFrame(my_pipeline.named_steps['imputer'].transform(X_new), columns=X_new.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    HR (BPM)   SpO2 (%)  TEMP (*C) Predictions\n",
      "0         90         80       37.0    Abnormal\n",
      "1         60        100       38.0    Abnormal\n",
      "2         90         70       38.0    Abnormal\n",
      "3        100         60       38.0    Abnormal\n",
      "4         90        100       36.5    Abnormal\n",
      "5         94         97       36.5      Normal\n",
      "6         80         95       37.0    Abnormal\n",
      "7         94        995       36.0    Abnormal\n",
      "8         94         95       36.0    Abnormal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predictions = my_pipeline.named_steps['model'].predict(X_new_imputed)\n",
    "\n",
    "# Add predictions to the original data\n",
    "new_data['Predictions'] = predictions\n",
    "\n",
    "# Display the predictions\n",
    "print(new_data[[ ' HR (BPM)', ' SpO2 (%)', 'TEMP (*C)', 'Predictions']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
